{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import load, dump\n",
    "from torch.optim import lr_scheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/train.parquet.gzip'\n",
    "test_path = '../data/test.parquet.gzip'\n",
    "pred_cols = [\"Mean_BMI\",\"Median_BMI\",\"Unmet_Need_Rate\",\"Under5_Mortality_Rate\",\"Skilled_Birth_Attendant_Rate\",\"Stunted_Rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_imp_features = load('../data/low_imp_features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(input_path)\n",
    "train = train[~train.index.duplicated(keep='first')]\n",
    "train = train.drop(low_imp_features, axis=1)\n",
    "X = train.drop(pred_cols, axis=1)\n",
    "y = train[pred_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "class my_metric(Metric):\n",
    "    \"\"\"\n",
    "    MCRMSE.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._name = \"MCRMSE\" # write an understandable name here\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "        \"\"\"\n",
    "        # loop over each column and calculate error\n",
    "        errors = []\n",
    "        for i in range(y_true.shape[1]):\n",
    "            errors.append(np.sqrt(mean_squared_error(y_true[:,i], y_score[:,i])))\n",
    "        ans = np.mean(errors)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabNetRegressor(n_d=32, n_a=32, n_steps=15, n_independent=5, n_shared=5, scheduler_fn=lr_scheduler.ReduceLROnPlateau\n",
    "                        , gamma=3.3, lambda_sparse=0.01, momentum=0.3, seed=42)\n",
    "model.fit(\n",
    "  X_train.values, y_train.values,\n",
    "  eval_set=[(X_valid.values, y_valid.values)],\n",
    "  eval_metric=['rmse', my_metric],\n",
    "  patience=0,\n",
    "  batch_size=2048,\n",
    "  max_epochs=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6403.25276| val_0_unsup_loss_numpy: 4442.6572265625|  0:00:03s\n",
      "epoch 1  | loss: 4238.53732| val_0_unsup_loss_numpy: 4364.6748046875|  0:00:06s\n",
      "epoch 2  | loss: 3995.94473| val_0_unsup_loss_numpy: 4460.5576171875|  0:00:10s\n",
      "epoch 3  | loss: 3505.3523| val_0_unsup_loss_numpy: 4503.0830078125|  0:00:13s\n",
      "epoch 4  | loss: 2958.54427| val_0_unsup_loss_numpy: 4518.609375|  0:00:17s\n",
      "epoch 5  | loss: 2433.05314| val_0_unsup_loss_numpy: 4531.73779296875|  0:00:20s\n",
      "epoch 6  | loss: 1905.00614| val_0_unsup_loss_numpy: 4584.5244140625|  0:00:24s\n",
      "epoch 7  | loss: 2331.02901| val_0_unsup_loss_numpy: 4590.29931640625|  0:00:27s\n",
      "epoch 8  | loss: 2073.26027| val_0_unsup_loss_numpy: 4609.150390625|  0:00:30s\n",
      "epoch 9  | loss: 763.89953| val_0_unsup_loss_numpy: 4599.2548828125|  0:00:34s\n",
      "epoch 10 | loss: 559.83456| val_0_unsup_loss_numpy: 4594.5634765625|  0:00:37s\n",
      "epoch 11 | loss: 397.22112| val_0_unsup_loss_numpy: 4577.89013671875|  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_unsup_loss_numpy = 4364.6748046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_a changed from 64 to 8\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 64 to 8\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_steps changed from 5 to 3\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:231: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1710.9842| train_MCRMSE: 30.73022| valid_MCRMSE: 30.8094 |  0:00:03s\n",
      "epoch 1  | loss: 1192.82632| train_MCRMSE: 25.8005 | valid_MCRMSE: 25.83953|  0:00:07s\n",
      "epoch 2  | loss: 730.05097| train_MCRMSE: 19.99073| valid_MCRMSE: 20.02507|  0:00:10s\n",
      "epoch 3  | loss: 391.79099| train_MCRMSE: 18.47279| valid_MCRMSE: 18.58014|  0:00:14s\n",
      "epoch 4  | loss: 302.03982| train_MCRMSE: 14.70228| valid_MCRMSE: 14.7522 |  0:00:18s\n",
      "epoch 5  | loss: 277.39871| train_MCRMSE: 15.0459 | valid_MCRMSE: 15.1344 |  0:00:21s\n",
      "epoch 6  | loss: 263.3166| train_MCRMSE: 14.17586| valid_MCRMSE: 14.26668|  0:00:25s\n",
      "epoch 7  | loss: 255.23289| train_MCRMSE: 13.6484 | valid_MCRMSE: 13.72392|  0:00:28s\n",
      "epoch 8  | loss: 248.30778| train_MCRMSE: 13.3284 | valid_MCRMSE: 13.41342|  0:00:32s\n",
      "epoch 9  | loss: 245.01815| train_MCRMSE: 13.3023 | valid_MCRMSE: 13.34598|  0:00:36s\n",
      "epoch 10 | loss: 241.91678| train_MCRMSE: 13.12555| valid_MCRMSE: 13.20233|  0:00:39s\n",
      "epoch 11 | loss: 237.21779| train_MCRMSE: 13.03499| valid_MCRMSE: 13.0837 |  0:00:43s\n",
      "epoch 12 | loss: 236.80543| train_MCRMSE: 12.91929| valid_MCRMSE: 12.9649 |  0:00:46s\n",
      "epoch 13 | loss: 235.04289| train_MCRMSE: 12.7699 | valid_MCRMSE: 12.86095|  0:00:50s\n",
      "epoch 14 | loss: 232.30781| train_MCRMSE: 12.73429| valid_MCRMSE: 12.8194 |  0:00:54s\n",
      "epoch 15 | loss: 230.76799| train_MCRMSE: 12.71467| valid_MCRMSE: 12.80196|  0:00:57s\n",
      "epoch 16 | loss: 230.42737| train_MCRMSE: 12.62446| valid_MCRMSE: 12.6892 |  0:01:01s\n",
      "epoch 17 | loss: 229.24114| train_MCRMSE: 12.58654| valid_MCRMSE: 12.64524|  0:01:04s\n",
      "epoch 18 | loss: 226.78575| train_MCRMSE: 12.55715| valid_MCRMSE: 12.63869|  0:01:08s\n",
      "epoch 19 | loss: 224.94821| train_MCRMSE: 12.51192| valid_MCRMSE: 12.60581|  0:01:12s\n",
      "epoch 20 | loss: 223.504 | train_MCRMSE: 12.44599| valid_MCRMSE: 12.51695|  0:01:15s\n",
      "epoch 21 | loss: 222.27858| train_MCRMSE: 12.38124| valid_MCRMSE: 12.49299|  0:01:19s\n",
      "epoch 22 | loss: 222.08996| train_MCRMSE: 12.43355| valid_MCRMSE: 12.51018|  0:01:22s\n",
      "epoch 23 | loss: 221.16816| train_MCRMSE: 12.42531| valid_MCRMSE: 12.52897|  0:01:26s\n",
      "epoch 24 | loss: 219.61991| train_MCRMSE: 12.3026 | valid_MCRMSE: 12.4125 |  0:01:30s\n",
      "epoch 25 | loss: 219.40211| train_MCRMSE: 12.2423 | valid_MCRMSE: 12.37296|  0:01:33s\n",
      "epoch 26 | loss: 218.58415| train_MCRMSE: 12.20176| valid_MCRMSE: 12.32517|  0:01:37s\n",
      "epoch 27 | loss: 216.75837| train_MCRMSE: 12.14076| valid_MCRMSE: 12.24621|  0:01:40s\n",
      "epoch 28 | loss: 216.99225| train_MCRMSE: 12.0981 | valid_MCRMSE: 12.25704|  0:01:44s\n",
      "epoch 29 | loss: 216.17698| train_MCRMSE: 12.06313| valid_MCRMSE: 12.22225|  0:01:48s\n",
      "epoch 30 | loss: 215.02507| train_MCRMSE: 11.98942| valid_MCRMSE: 12.15588|  0:01:51s\n",
      "epoch 31 | loss: 214.62241| train_MCRMSE: 11.98118| valid_MCRMSE: 12.14162|  0:01:55s\n",
      "epoch 32 | loss: 215.19062| train_MCRMSE: 11.90992| valid_MCRMSE: 12.06476|  0:01:58s\n",
      "epoch 33 | loss: 214.05827| train_MCRMSE: 11.93651| valid_MCRMSE: 12.10228|  0:02:02s\n",
      "epoch 34 | loss: 214.60225| train_MCRMSE: 11.85164| valid_MCRMSE: 12.05884|  0:02:06s\n",
      "epoch 35 | loss: 213.67854| train_MCRMSE: 11.79819| valid_MCRMSE: 12.02059|  0:02:09s\n",
      "epoch 36 | loss: 212.55594| train_MCRMSE: 11.79051| valid_MCRMSE: 12.03022|  0:02:13s\n",
      "epoch 37 | loss: 213.18337| train_MCRMSE: 11.78026| valid_MCRMSE: 11.99298|  0:02:17s\n",
      "epoch 38 | loss: 211.94697| train_MCRMSE: 11.75428| valid_MCRMSE: 11.98524|  0:02:20s\n",
      "epoch 39 | loss: 212.17629| train_MCRMSE: 11.74764| valid_MCRMSE: 11.99806|  0:02:24s\n",
      "epoch 40 | loss: 210.7836| train_MCRMSE: 11.69093| valid_MCRMSE: 11.94525|  0:02:27s\n",
      "epoch 41 | loss: 211.05887| train_MCRMSE: 11.69933| valid_MCRMSE: 11.9539 |  0:02:31s\n",
      "epoch 42 | loss: 210.74555| train_MCRMSE: 11.7652 | valid_MCRMSE: 12.05206|  0:02:35s\n",
      "epoch 43 | loss: 210.51418| train_MCRMSE: 11.77252| valid_MCRMSE: 12.01994|  0:02:38s\n",
      "epoch 44 | loss: 210.42124| train_MCRMSE: 11.68245| valid_MCRMSE: 11.94628|  0:02:42s\n",
      "epoch 45 | loss: 209.16782| train_MCRMSE: 11.7035 | valid_MCRMSE: 11.97153|  0:02:45s\n",
      "epoch 46 | loss: 209.76761| train_MCRMSE: 11.67716| valid_MCRMSE: 11.94316|  0:02:49s\n",
      "epoch 47 | loss: 209.72861| train_MCRMSE: 11.67099| valid_MCRMSE: 11.95558|  0:02:53s\n",
      "epoch 48 | loss: 208.26509| train_MCRMSE: 11.66179| valid_MCRMSE: 11.95021|  0:02:56s\n",
      "epoch 49 | loss: 208.56806| train_MCRMSE: 11.71333| valid_MCRMSE: 11.95723|  0:03:00s\n",
      "epoch 50 | loss: 208.59496| train_MCRMSE: 11.65556| valid_MCRMSE: 11.9475 |  0:03:03s\n",
      "epoch 51 | loss: 208.43196| train_MCRMSE: 11.61833| valid_MCRMSE: 11.90768|  0:03:07s\n",
      "epoch 52 | loss: 207.10978| train_MCRMSE: 11.63795| valid_MCRMSE: 11.95794|  0:03:11s\n",
      "epoch 53 | loss: 208.57751| train_MCRMSE: 11.60964| valid_MCRMSE: 11.91825|  0:03:14s\n",
      "epoch 54 | loss: 208.09771| train_MCRMSE: 11.63501| valid_MCRMSE: 11.92719|  0:03:18s\n",
      "epoch 55 | loss: 207.03826| train_MCRMSE: 11.64692| valid_MCRMSE: 11.95566|  0:03:21s\n",
      "epoch 56 | loss: 207.37022| train_MCRMSE: 11.65898| valid_MCRMSE: 11.95385|  0:03:25s\n",
      "epoch 57 | loss: 207.26778| train_MCRMSE: 11.63583| valid_MCRMSE: 11.94397|  0:03:29s\n",
      "epoch 58 | loss: 206.59085| train_MCRMSE: 11.6338 | valid_MCRMSE: 11.92687|  0:03:32s\n",
      "epoch 59 | loss: 206.88718| train_MCRMSE: 11.58458| valid_MCRMSE: 11.91965|  0:03:36s\n",
      "epoch 60 | loss: 206.61408| train_MCRMSE: 11.57795| valid_MCRMSE: 11.8933 |  0:03:40s\n",
      "epoch 61 | loss: 205.74977| train_MCRMSE: 11.57666| valid_MCRMSE: 11.88846|  0:03:43s\n",
      "epoch 62 | loss: 206.28651| train_MCRMSE: 11.56899| valid_MCRMSE: 11.87655|  0:03:47s\n",
      "epoch 63 | loss: 206.16249| train_MCRMSE: 11.56416| valid_MCRMSE: 11.87942|  0:03:50s\n",
      "epoch 64 | loss: 204.87046| train_MCRMSE: 11.52935| valid_MCRMSE: 11.87816|  0:03:54s\n",
      "epoch 65 | loss: 204.13668| train_MCRMSE: 11.54138| valid_MCRMSE: 11.89166|  0:03:58s\n",
      "epoch 66 | loss: 205.04644| train_MCRMSE: 11.52758| valid_MCRMSE: 11.85467|  0:04:01s\n",
      "epoch 67 | loss: 203.66146| train_MCRMSE: 11.53099| valid_MCRMSE: 11.90554|  0:04:05s\n",
      "epoch 68 | loss: 204.81141| train_MCRMSE: 11.50898| valid_MCRMSE: 11.86523|  0:04:08s\n",
      "epoch 69 | loss: 204.08709| train_MCRMSE: 11.50981| valid_MCRMSE: 11.86684|  0:04:12s\n",
      "epoch 70 | loss: 204.00218| train_MCRMSE: 11.49483| valid_MCRMSE: 11.83667|  0:04:16s\n",
      "epoch 71 | loss: 202.93458| train_MCRMSE: 11.49101| valid_MCRMSE: 11.85828|  0:04:19s\n",
      "epoch 72 | loss: 203.38815| train_MCRMSE: 11.48284| valid_MCRMSE: 11.85268|  0:04:23s\n",
      "epoch 73 | loss: 202.95987| train_MCRMSE: 11.47482| valid_MCRMSE: 11.84262|  0:04:26s\n",
      "epoch 74 | loss: 203.87776| train_MCRMSE: 11.49106| valid_MCRMSE: 11.87965|  0:04:30s\n",
      "epoch 75 | loss: 202.89695| train_MCRMSE: 11.45792| valid_MCRMSE: 11.84346|  0:04:33s\n",
      "epoch 76 | loss: 202.29702| train_MCRMSE: 11.48492| valid_MCRMSE: 11.85683|  0:04:37s\n",
      "epoch 77 | loss: 202.46014| train_MCRMSE: 11.44869| valid_MCRMSE: 11.82841|  0:04:40s\n",
      "epoch 78 | loss: 202.82441| train_MCRMSE: 11.44865| valid_MCRMSE: 11.83476|  0:04:44s\n",
      "epoch 79 | loss: 204.02259| train_MCRMSE: 11.44152| valid_MCRMSE: 11.81117|  0:04:48s\n",
      "epoch 80 | loss: 201.95958| train_MCRMSE: 11.50556| valid_MCRMSE: 11.89767|  0:04:51s\n",
      "epoch 81 | loss: 201.38025| train_MCRMSE: 11.4335 | valid_MCRMSE: 11.82208|  0:04:55s\n",
      "epoch 82 | loss: 203.54813| train_MCRMSE: 11.43616| valid_MCRMSE: 11.8283 |  0:04:59s\n",
      "epoch 83 | loss: 201.85306| train_MCRMSE: 11.44207| valid_MCRMSE: 11.81293|  0:05:02s\n",
      "epoch 84 | loss: 202.04998| train_MCRMSE: 11.45391| valid_MCRMSE: 11.82126|  0:05:06s\n",
      "epoch 85 | loss: 201.42039| train_MCRMSE: 11.42359| valid_MCRMSE: 11.79985|  0:05:09s\n",
      "epoch 86 | loss: 201.36476| train_MCRMSE: 11.46803| valid_MCRMSE: 11.87275|  0:05:13s\n",
      "epoch 87 | loss: 202.49786| train_MCRMSE: 11.40946| valid_MCRMSE: 11.81484|  0:05:17s\n",
      "epoch 88 | loss: 201.02612| train_MCRMSE: 11.43611| valid_MCRMSE: 11.81972|  0:05:20s\n",
      "epoch 89 | loss: 202.07907| train_MCRMSE: 11.47761| valid_MCRMSE: 11.85708|  0:05:24s\n",
      "epoch 90 | loss: 201.35619| train_MCRMSE: 11.47374| valid_MCRMSE: 11.86604|  0:05:28s\n",
      "epoch 91 | loss: 201.13888| train_MCRMSE: 11.42784| valid_MCRMSE: 11.81615|  0:05:31s\n",
      "epoch 92 | loss: 201.32938| train_MCRMSE: 11.40611| valid_MCRMSE: 11.82419|  0:05:35s\n",
      "epoch 93 | loss: 201.68052| train_MCRMSE: 11.40002| valid_MCRMSE: 11.7896 |  0:05:38s\n",
      "epoch 94 | loss: 201.69288| train_MCRMSE: 11.42682| valid_MCRMSE: 11.82229|  0:05:42s\n",
      "epoch 95 | loss: 201.53341| train_MCRMSE: 11.40952| valid_MCRMSE: 11.82458|  0:05:46s\n",
      "epoch 96 | loss: 200.75183| train_MCRMSE: 11.43248| valid_MCRMSE: 11.84587|  0:05:49s\n",
      "epoch 97 | loss: 200.83748| train_MCRMSE: 11.39374| valid_MCRMSE: 11.79523|  0:05:53s\n",
      "epoch 98 | loss: 201.15154| train_MCRMSE: 11.39788| valid_MCRMSE: 11.79864|  0:05:57s\n",
      "epoch 99 | loss: 199.77263| train_MCRMSE: 11.38408| valid_MCRMSE: 11.78468|  0:06:00s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_valid_MCRMSE = 11.78468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml2/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train.values,\n",
    "    eval_set=[X_valid.values],\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "model = TabNetRegressor(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    n_d=64,\n",
    "    n_a=64,\n",
    "    n_steps=5,\n",
    "    gamma=2.3,\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train=X_train.values, y_train=y_train.values,\n",
    "    eval_set=[(X_train.values, y_train.values), (X_valid.values, y_valid.values)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=[my_metric],\n",
    "    from_unsupervised=unsupervised_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('../data/test.parquet.gzip')\n",
    "test = test.drop(columns=low_imp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test.values)\n",
    "out = pd.DataFrame(y_pred, columns=pred_cols)\n",
    "out['DHSID'] = test.index\n",
    "out = out[['DHSID'] + pred_cols]\n",
    "out.to_csv('../submission/tabnet_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
